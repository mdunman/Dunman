{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('q3.csv',header=None)\n",
    "y = list(data[54])\n",
    "print(list(y[0:5]))\n",
    "data = data.drop(labels=54,axis=1)\n",
    "print(\"data shape = \"+ str(data.shape))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "print(len(X_train)/(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A (i)\n",
    "# Naive Bayes\n",
    "p0 = y.count(0) / len(y)\n",
    "p1 = y.count(1) / len(y)\n",
    "ps = np.array([p0,p1])\n",
    "nb = GaussianNB(priors=ps)\n",
    "nb.fit(X_train, y_train)\n",
    "round(sum(nb.predict(X_test)==y_test)/len(y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "round(sum(lr.predict(X_test)==y_test)/len(y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "print(\"K Neighbors\")\n",
    "for i in range(2,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    print(str(i) +\": \" + str(round(sum(knn.predict(X_test)==y_test)/len(y_test)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A (ii)\n",
    "data2 = np.array(data.loc[:,0:1])\n",
    "X_train2 = np.array(X_train.loc[:,0:1])\n",
    "X_test2 = np.array(X_test.loc[:,0:1])\n",
    "h = 0.02\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "x_min, x_max = data2[:, 0].min() - 1, data2[:, 0].max() + 1\n",
    "y_min, y_max = data2[:, 1].min() - 1, data2[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "p0 = y.count(0) / len(y)\n",
    "p1 = y.count(1) / len(y)\n",
    "ps = np.array([p0,p1])\n",
    "nb2 = GaussianNB(priors=ps)\n",
    "nb2.fit(X_train2, y_train)\n",
    "\n",
    "Z = nb2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "ptr = plt.scatter(X_train2[:, 0], X_train2[:, 1], c=y_train, marker='.', s=80, cmap=cmap_bold)\n",
    "pte = plt.scatter(X_test2[:, 0], X_test2[:, 1], c=y_test, marker='*', s=80, cmap=cmap_bold)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Naive Bayes\")\n",
    "plt.legend((ptr, pte), ['Training Point', 'Test Point'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train2, y_train)\n",
    "\n",
    "Z = lr2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "ptr = plt.scatter(X_train2[:, 0], X_train2[:, 1], c=y_train, marker='.', s=80, cmap=cmap_bold)\n",
    "pte = plt.scatter(X_test2[:, 0], X_test2[:, 1], c=y_test, marker='*', s=80, cmap=cmap_bold)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.legend((ptr, pte), ['Training Point', 'Test Point'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "plt.figure(figsize=(11,11))\n",
    "for i in range(2,11):\n",
    "    knn2 = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn2.fit(X_train2,y_train)\n",
    "\n",
    "    Z = knn2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.subplot(3,3,i-1)\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "    ptr = plt.scatter(X_train2[:, 0], X_train2[:, 1], c=y_train, marker='.', s=50, cmap=cmap_bold)\n",
    "    pte = plt.scatter(X_test2[:, 0], X_test2[:, 1], c=y_test, marker='*', cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"KNN: \" + str(i) + \" Neighbors\")\n",
    "    plt.legend((ptr, pte), ['Training Point', 'Test Point'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part B\n",
    "data = sio.loadmat('data.mat')['data'].T\n",
    "print(data.shape)\n",
    "labels = sio.loadmat('label.mat')['trueLabel'][0]\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 6:\n",
    "        y.append(1)\n",
    "    if labels[i] == 2:\n",
    "        y.append(0)\n",
    "print(labels[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "print(len(X_train)/(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "p0 = y.count(0) / len(y)\n",
    "p1 = y.count(1) / len(y)\n",
    "ps = np.array([p0,p1])\n",
    "nb = GaussianNB(priors=ps)\n",
    "nb.fit(X_train, y_train)\n",
    "round(sum(nb.predict(X_test)==y_test)/len(y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "round(sum(lr.predict(X_test)==y_test)/len(y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "print(\"K Neighbors\")\n",
    "for i in range(2,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    print(str(i) +\": \" + str(round(sum(knn.predict(X_test)==y_test)/len(y_test)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
